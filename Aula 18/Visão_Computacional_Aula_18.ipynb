{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Visão_Computacional_Aula_18.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD3EUCBe3W2c"
      },
      "source": [
        "## **VISÃO COMPUTACIONAL - AULA 18**\n",
        "\n",
        "**Objetivos da aula:**\n",
        "\n",
        "*   apresentar o processo completo de visão estéreo\n",
        "*   apresentar o conceito de disparidade e mapa de profundidade\n",
        "*   praticar com reconstrução 3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF2VN8sR1cBG"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdxkXIFOHtYx"
      },
      "source": [
        "#### <b> CARGA DOS DADOS PARA RECONSTRUÇÃO 3D <b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4-5f6uM3xHC"
      },
      "source": [
        "\n",
        "Esta sequencia de células é somente para descompactar o nosso arquivo de dados, formados pelas imagens e dados de calibração das câmeras. Em seguida, lemos os dados destes arquivos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0WoYlwZ2mrC",
        "outputId": "1e25a907-ea23-48e6-c2eb-28eb1a73289f"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"data_road.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN1Fe-kH1cBG"
      },
      "source": [
        "data_folder_left = \"data_road/training/image_2/\"\n",
        "data_folder_right = \"data_road/training_right/image_3/\"\n",
        "data_folder_calib = \"data_road/training/calib/\"\n",
        "cat = ['uu', 'uum', 'um']\n",
        "IDX_LEN = 6"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz0fzOwI1cBG"
      },
      "source": [
        "idx_num = 1\n",
        "cat_idx = 2\n",
        "fname = cat[cat_idx]+'_'+str(idx_num).zfill(IDX_LEN)\n",
        "img_fname = fname + '.png'\n",
        "calib_fname = fname + '.txt'"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vx9vf3P1cBG"
      },
      "source": [
        "img_left_color = cv2.imread(data_folder_left + img_fname)\n",
        "img_right_color = cv2.imread(data_folder_right + img_fname)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1L9350I1cBG"
      },
      "source": [
        "img_left_bw = cv2.blur(cv2.cvtColor(img_left_color, cv2.COLOR_RGB2GRAY),(5,5))\n",
        "img_right_bw = cv2.blur(cv2.cvtColor(img_right_color, cv2.COLOR_RGB2GRAY),(5,5))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07tevpViHbnX"
      },
      "source": [
        "A imagem capturada pela câmera esquerda é mostrada abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_auzSZlLHVqR"
      },
      "source": [
        "cv2_imshow(img_left_bw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC-RMTEfHnKM"
      },
      "source": [
        "A imagem capturada pela câmera direita é mostrada abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5yxXtwC1cBH"
      },
      "source": [
        "cv2_imshow(img_right_bw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su8CIfEBIMf_"
      },
      "source": [
        "Abaixo, temos a leitura dos dados de calibração das câmeras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW8NqLETH_tM"
      },
      "source": [
        "\n",
        "matrix_type_1 = 'P2'\n",
        "matrix_type_2 = 'P3'\n",
        "\n",
        "calib_file = data_folder_calib + calib_fname\n",
        "with open(calib_file, 'r') as f:\n",
        "    fin = f.readlines()\n",
        "    for line in fin:\n",
        "        if line[:2] == matrix_type_1:\n",
        "            calib_matrix_1 = np.array(line[4:].strip().split(\" \")).astype('float32').reshape(3,-1)\n",
        "        elif line[:2] == matrix_type_2:\n",
        "            calib_matrix_2 = np.array(line[4:].strip().split(\" \")).astype('float32').reshape(3,-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t73O2uFITIc"
      },
      "source": [
        "#### <b> CÁLCULO DE DISPARIDADES </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwnKnoVHI-0G"
      },
      "source": [
        "A disparidade é qualquer mudança entre a posição de objetos\n",
        "no par de imagens, e é inversamente proporcional à distância do\n",
        "objeto até a lente da câmera. Portanto a distância pode ser\n",
        "calculada obtendo a disparidade de um par estéreo, e a disparidade\n",
        "pode ser estimada através da correspondência dos objetos nas\n",
        "imagens.\n",
        "\n",
        "A OpenCV disponibiliza uma implementação do Algoritmo de Emparelhamento de Blocos (Bock Matching Algorithm). \n",
        "\n",
        "Referência: https://en.wikipedia.org/wiki/Block-matching_algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "962WReQp1cBI"
      },
      "source": [
        "stereo = cv2.StereoBM_create(numDisparities=96, blockSize=11)\n",
        "disparity = stereo.compute(img_left_bw,img_right_bw)\n",
        "img = disparity.copy()\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtVfmMA0J6V-"
      },
      "source": [
        "#### <b>EXERCÍCIO</b>\n",
        "\n",
        "Um dos parâmetros de configuração para cálculo de disparidades é o numDisparities. O que este parâmetro controla ? Por que ele precisa ser múltiplo de 16 ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORcV0LiZKkXw"
      },
      "source": [
        "#faça seus experimentos aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty584nDHMRci"
      },
      "source": [
        "#### <b>EXERCÍCIO</b>\n",
        "\n",
        "O segundo parâmetro é o blockSize... o que controla a configuração deste parâmetro ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgxdm2dRMdhr"
      },
      "source": [
        "#faça seus experimentos aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0yd4okEMi5E"
      },
      "source": [
        "#### <b> RECONSTRUÇÃO 3D </b>\n",
        "\n",
        "A partir do mapa de disparidades, podemos obter a profundidade de cada ponto do par estéreo. Isto gera o chamado mapa de profundidade. \n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Sing_Bing_Kang/publication/2313285/figure/fig1/AS:341573188505604@1458448802555/Relationship-between-the-baseline-b-disparity-d-focal-length-f-and-depth-z_W640.jpg\"> </img>\n",
        "\n",
        "Isto é feito pela função stereoRectify da OpenCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYDvATnB1cBI"
      },
      "source": [
        "# Calculate depth-to-disparity\n",
        "cam1 = calib_matrix_1[:,:3] # left image - P2\n",
        "cam2 = calib_matrix_2[:,:3] # right image - P3\n",
        "\n",
        "Tmat = np.array([0.54, 0., 0.])\n",
        "\n",
        "rev_proj_matrix = np.zeros((4,4))\n",
        "\n",
        "cv2.stereoRectify(cameraMatrix1 = cam1,cameraMatrix2 = cam2, \\\n",
        "                  distCoeffs1 = 0, distCoeffs2 = 0, \\\n",
        "                  imageSize = img_left_color.shape[:2], \\\n",
        "                  R = np.identity(3), T = Tmat, \\\n",
        "                  R1 = None, R2 = None, \\\n",
        "                  P1 =  None, P2 =  None, Q = rev_proj_matrix);\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOPkTbK0OH3D"
      },
      "source": [
        "O resultado principal da stereoRectify é determinar a matriz inversa de projeção de uma das câmeras do setup de visão estéreo. Uma vez que tenhamos esta matriz, podemos reconstruir a estrutura 3D de qualquer objeto. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbd8lAba1cBI"
      },
      "source": [
        "points = cv2.reprojectImageTo3D(img, rev_proj_matrix)\n",
        "\n",
        "#reflect on x axis\n",
        "reflect_matrix = np.identity(3)\n",
        "reflect_matrix[0] *= -1\n",
        "points = np.matmul(points,reflect_matrix)\n",
        "\n",
        "#extract colors from image\n",
        "colors = cv2.cvtColor(img_left_color, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#filter by min disparity\n",
        "mask = img > img.min()\n",
        "out_points = points[mask]\n",
        "out_colors = colors[mask]\n",
        "\n",
        "#filter by dimension\n",
        "idx = np.fabs(out_points[:,0]) < 4.5\n",
        "out_points = out_points[idx]\n",
        "out_colors = out_colors.reshape(-1, 3)\n",
        "out_colors = out_colors[idx]\n",
        "\n",
        "print(\"Pontos Reconstruídos:\")\n",
        "print(points[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBazHU53O2Fz"
      },
      "source": [
        "#### <b> ARMAZENAMENTO DA NUVEM DE PONTOS </b>\n",
        "\n",
        "A nuvem de pontos reconstruída anteriormente, pode ser armazenada de diversas maneiras. Uma das maneiras comuns é salvar os resultado no formato PLY.\n",
        "\n",
        "Referência: https://en.wikipedia.org/wiki/PLY_(file_format)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tame8OQCGHwM"
      },
      "source": [
        "def write_ply(fn, verts, colors):\n",
        "    ply_header = '''ply\n",
        "    format ascii 1.0\n",
        "    element vertex %(vert_num)d\n",
        "    property float x\n",
        "    property float y\n",
        "    property float z\n",
        "    property uchar red\n",
        "    property uchar green\n",
        "    property uchar blue\n",
        "    end_header\n",
        "    '''\n",
        "    out_colors = colors.copy()\n",
        "    verts = verts.reshape(-1, 3)\n",
        "    verts = np.hstack([verts, out_colors])\n",
        "    with open(fn, 'wb') as f:\n",
        "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
        "        np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')\n",
        "\n",
        "write_ply('out.ply', out_points, out_colors)\n",
        "print('%s saved' % 'out.ply')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjXf7L4FPa1U"
      },
      "source": [
        "#### <b> VERIFICAÇÃO DOS PONTOS PROJETADOS </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8p8M5_WPiB4"
      },
      "source": [
        "Uma vez que tenhamos reconstruídos os pontos, podemos verificar a qualidade da reconstruída, reprojetando os pontos reconstruídos para produzir uma nova imgame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDHIc53x1cBI"
      },
      "source": [
        "reflected_pts = np.matmul(out_points, reflect_matrix)\n",
        "projected_img,_ = cv2.projectPoints(reflected_pts, np.identity(3), np.array([0., 0., 0.]), \\\n",
        "                          cam2[:3,:3], np.array([0., 0., 0., 0.]))\n",
        "projected_img = projected_img.reshape(-1, 2)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbVw8A2e1cBI"
      },
      "source": [
        "blank_img = np.zeros(img_left_color.shape, 'uint8')\n",
        "img_colors = img_right_color[mask][idx].reshape(-1,3)\n",
        "\n",
        "for i, pt in enumerate(projected_img):\n",
        "    pt_x = int(pt[0])\n",
        "    pt_y = int(pt[1])\n",
        "    if pt_x > 0 and pt_y > 0:\n",
        "        # use the BGR format to match the original image type\n",
        "        col = (int(img_colors[i, 2]), int(img_colors[i, 1]), int(img_colors[i, 0]))\n",
        "        cv2.circle(blank_img, (pt_x, pt_y), 1, col)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQPQchko1cBI"
      },
      "source": [
        "cv2_imshow(blank_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K0oqIv2P5Bj"
      },
      "source": [
        "#### <b>EXERCÍCIO</b>\n",
        "\n",
        "Como a geração do mapa de disparidades controla a qualidade dos pontos reconstruídos ? Faça experimentos para verificar como a qualidade do mapa de disparidades controla a qualidade da reconstrução."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLyJafJQ1cBJ"
      },
      "source": [
        "#faça seus experimentos aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4YCYdBzQWRP"
      },
      "source": [
        "#### <B> PRÓXIMOS EVENTOS </b>\n",
        "\n",
        "<b> 24 NOV </b>  - REVISÃO PARA PROVA P2\n",
        "\n",
        "<b> 26 NOV </b>  - PROVA P2\n",
        "\n",
        "<b> 07 DEC </b>  - PROJETO II\n"
      ]
    }
  ]
}